version: '3.7'

services:
  namenode:
    build: .
    container_name: namenode
    hostname: namenode
    ports:
      - "9870:9870"   # Namenode Web UI
      - "8088:8088"   # YARN Web UI
      - "9000:9000"   # HDFS
      - "22:22"       # SSH
    command: >
      bash -c "
      hdfs namenode -format -force;
      start-dfs.sh;
      start-yarn.sh;
      tail -f /dev/null"
    volumes:
      - namenode-data:/opt/hadoop/data/namenode
      - ./logs:/opt/hadoop/logs
    networks:
      hadoop-net:
        aliases:
          - namenode
    environment:
      - HDFS_NAMENODE_USER=root
      - YARN_RESOURCEMANAGER_USER=root
      - CLUSTER_MODE=multi

  datanode1:
    build: .
    container_name: datanode1
    hostname: datanode1
    volumes:
      - datanode1-data:/opt/hadoop/data/datanode
    networks:
      hadoop-net:
    depends_on:
      - namenode
    environment:
      - HDFS_DATANODE_USER=root
      - YARN_NODEMANAGER_USER=root
      - CLUSTER_MODE=multi

  datanode2:
    build: .
    container_name: datanode2
    hostname: datanode2
    volumes:
      - datanode2-data:/opt/hadoop/data/datanode
    networks:
      hadoop-net:
    depends_on:
      - namenode
    environment:
      - HDFS_DATANODE_USER=root
      - YARN_NODEMANAGER_USER=root
      - CLUSTER_MODE=multi

  datanode3:
    build: .
    container_name: datanode3
    hostname: datanode3
    volumes:
      - datanode3-data:/opt/hadoop/data/datanode
    networks:
      hadoop-net:
    depends_on:
      - namenode
    environment:
      - HDFS_DATANODE_USER=root
      - YARN_NODEMANAGER_USER=root
      - CLUSTER_MODE=multi

  # Add Spark services
  spark-master:
    image: bitnami/spark:3.5
    hostname: spark-master
    container_name: spark-master
    ports:
      - "8080:8080"  # Spark UI
      - "7077:7077"  # Spark master port
    volumes:
      - ./spark-config:/opt/bitnami/spark/conf
      - hadoop-config:/opt/hadoop/etc/hadoop:ro
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENABLED=no
      - SPARK_HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
    networks:
      - hadoop-net
    depends_on:
      - namenode

  spark-worker:
    image: bitnami/spark:3.5
    hostname: spark-worker
    container_name: spark-worker1
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
    volumes:
      - hadoop-config:/opt/hadoop/etc/hadoop:ro
    networks:
      - hadoop-net
    depends_on:
      - spark-master

volumes:
  namenode-data:
  datanode1-data:
  datanode2-data:
  datanode3-data:
  hadoop-config:

networks:
  hadoop-net:
    driver: bridge